name: AI Evaluations

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
  workflow_dispatch: {}   # manual runs

permissions:
  contents: read
  pull-requests: write     # for PR comments
  issues: write            # for label ops if needed

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  ai-evaluations:
    name: AI Task Evaluations
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: npm

      - name: Install deps
        run: npm ci

      # ---- label gate (PRs only) ----
      - name: Gate by label (ai-evals)
        id: gate
        if: ${{ github.event_name == 'pull_request' }}
        uses: actions/github-script@v7
        with:
          script: |
            const labels = context.payload.pull_request?.labels?.map(l => l.name.toLowerCase()) || [];
            core.setOutput('run', labels.includes('ai-evals') ? 'true' : 'false');

      - name: Comment when skipped (no ai-evals label)
        if: ${{ github.event_name == 'pull_request' && steps.gate.outputs.run != 'true' }}
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.pull_request.number,
              body: "ðŸ›ˆ **AI Evaluations** skipped â€” add the `ai-evals` label to this PR (or run manually from *Actions*) to execute."
            });
            core.info("AI Evaluations gated by label; skipping.");

      # ---- decide script to run ----
      - name: Detect eval script
        id: has_script
        if: ${{ github.event_name != 'pull_request' || steps.gate.outputs.run == 'true' }}
        run: |
          node -e "const s=require('./package.json').scripts||{}; const pick=s['ai:eval:ci']?'ai:eval:ci':(s['ai:evaluate']?'ai:evaluate':''); console.log(pick);" > script_to_run.txt
          echo "name=$(cat script_to_run.txt)" >> $GITHUB_OUTPUT

      - name: Skip (no eval script present)
        if: ${{ (github.event_name != 'pull_request' || steps.gate.outputs.run == 'true') && steps.has_script.outputs.name == '' }}
        uses: actions/github-script@v7
        with:
          script: |
            const isPR = context.eventName === 'pull_request';
            const msg = "ðŸ›ˆ **AI Evaluations**: no `ai:eval:ci` or `ai:evaluate` script found â€” nothing to run.";
            if (isPR) {
              await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: context.payload.pull_request.number, body: msg });
            }
            core.info(msg);

      - name: Run AI evaluations
        if: ${{ (github.event_name != 'pull_request' || steps.gate.outputs.run == 'true') && steps.has_script.outputs.name != '' }}
        run: npm run -s ${{ steps.has_script.outputs.name }}

      - name: Upload eval artifacts (if any)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-evals-artifacts
          path: |
            artifacts/ai-evals/**
          if-no-files-found: ignore

      - name: Comment results (best-effort)
        if: ${{ (github.event_name == 'pull_request') && (steps.has_script.outputs.name != '' ) }}
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.pull_request.number,
              body: "âœ… **AI Evaluations** finished. See *Artifacts* â†’ `ai-evals-artifacts` for outputs."
            });
